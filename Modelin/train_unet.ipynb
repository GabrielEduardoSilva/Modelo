{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T09:13:03.124836Z",
     "start_time": "2018-11-09T09:13:02.276867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f81706551f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, RandomResizedCrop, RandomRotation, RandomHorizontalFlip, ToTensor, \\\n",
    "    Resize, RandomAffine, ColorJitter\n",
    "\n",
    "from dataset import MaskDataset, get_img_files\n",
    "from loss import dice_loss\n",
    "from nets.MobileNetV2_unet import MobileNetV2_unet\n",
    "from trainer import Trainer\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T09:13:03.130177Z",
     "start_time": "2018-11-09T09:13:03.126092Z"
    }
   },
   "outputs": [],
   "source": [
    "N_CV = 5\n",
    "BATCH_SIZE = 8\n",
    "LR = 1e-4\n",
    "\n",
    "N_EPOCHS = 100\n",
    "IMG_SIZE = 224\n",
    "RANDOM_STATE = 1\n",
    "\n",
    "EXPERIMENT = 'train_unet'\n",
    "OUT_DIR = 'outputs/{}'.format(EXPERIMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T09:13:03.255257Z",
     "start_time": "2018-11-09T09:13:03.131332Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(train_files, val_files):\n",
    "    train_transform = Compose([\n",
    "        ColorJitter(0.3, 0.3, 0.3, 0.3),\n",
    "        RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.2)),\n",
    "        RandomAffine(10.),\n",
    "        RandomRotation(13.),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "    ])\n",
    "    val_transform = Compose([\n",
    "        Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_loader = DataLoader(MaskDataset(train_files, train_transform),\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True,\n",
    "                              num_workers=4)\n",
    "    val_loader = DataLoader(MaskDataset(val_files, val_transform),\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def save_best_model(cv, model, df_hist):\n",
    "    if df_hist['val_loss'].tail(1).iloc[0] <= df_hist['val_loss'].min():\n",
    "        torch.save(model.state_dict(), '{}/{}-best.pth'.format(OUT_DIR, cv))\n",
    "\n",
    "\n",
    "def write_on_board(writer, df_hist):\n",
    "    row = df_hist.tail(1).iloc[0]\n",
    "\n",
    "    writer.add_scalars('{}/loss'.format(EXPERIMENT), {\n",
    "        'train': row.train_loss,\n",
    "        'val': row.val_loss,\n",
    "    }, row.epoch)\n",
    "\n",
    "\n",
    "def log_hist(df_hist):\n",
    "    last = df_hist.tail(1)\n",
    "    best = df_hist.sort_values('val_loss').head(1)\n",
    "    summary = pd.concat((last, best)).reset_index(drop=True)\n",
    "    summary['name'] = ['Last', 'Best']\n",
    "    logger.debug(summary[['name', 'epoch', 'train_loss', 'val_loss']])\n",
    "    logger.debug('')\n",
    "\n",
    "\n",
    "def run_cv():\n",
    "    image_files = get_img_files()\n",
    "    kf = KFold(n_splits=N_CV, random_state=RANDOM_STATE, shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kf.split(image_files)):\n",
    "        train_files = image_files[train_idx]\n",
    "        val_files = image_files[val_idx]\n",
    "\n",
    "        writer = SummaryWriter()\n",
    "\n",
    "        def on_after_epoch(m, df_hist):\n",
    "            save_best_model(n, m, df_hist)\n",
    "            write_on_board(writer, df_hist)\n",
    "            log_hist(df_hist)\n",
    "\n",
    "        criterion = dice_loss(scale=2)\n",
    "        data_loaders = get_data_loaders(train_files, val_files)\n",
    "        trainer = Trainer(data_loaders, criterion, device, on_after_epoch)\n",
    "\n",
    "        model = MobileNetV2_unet()\n",
    "        model.to(device)\n",
    "        optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        hist = trainer.train(model, optimizer, num_epochs=N_EPOCHS)\n",
    "        hist.to_csv('{}/{}-hist.csv'.format(OUT_DIR, n), index=False)\n",
    "\n",
    "        writer.close()\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T09:49:11.502712Z",
     "start_time": "2018-11-09T09:13:03.256353Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mhasHandlers():\n\u001b[1;32m      7\u001b[0m     logger\u001b[38;5;241m.\u001b[39maddHandler(logging\u001b[38;5;241m.\u001b[39mFileHandler(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.log\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(EXPERIMENT)))\n\u001b[0;32m----> 9\u001b[0m \u001b[43mrun_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 73\u001b[0m, in \u001b[0;36mrun_cv\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m data_loaders \u001b[38;5;241m=\u001b[39m get_data_loaders(train_files, val_files)\n\u001b[1;32m     71\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(data_loaders, criterion, device, on_after_epoch)\n\u001b[0;32m---> 73\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMobileNetV2_unet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     75\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLR)\n",
      "File \u001b[0;32m~/Documents/GitHub/Modelo/Modelin/nets/MobileNetV2_unet.py:36\u001b[0m, in \u001b[0;36mMobileNetV2_unet.__init__\u001b[0;34m(self, pre_trained)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_weights()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_trained \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_trained\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Downloads/Projeto/venv/lib/python3.8/site-packages/torch/serialization.py:595\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[1;32m    594\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Projeto/venv/lib/python3.8/site-packages/torch/serialization.py:774\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    772\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mUnpickler(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    773\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m--> 774\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    778\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Projeto/venv/lib/python3.8/site-packages/torch/serialization.py:730\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    728\u001b[0m     obj \u001b[38;5;241m=\u001b[39m data_type(size)\n\u001b[1;32m    729\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_torch_load_uninitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 730\u001b[0m     deserialized_objects[root_key] \u001b[38;5;241m=\u001b[39m \u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m storage \u001b[38;5;241m=\u001b[39m deserialized_objects[root_key]\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m view_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/Projeto/venv/lib/python3.8/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Downloads/Projeto/venv/lib/python3.8/site-packages/torch/serialization.py:151\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 151\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    153\u001b[0m             storage_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda, \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/Projeto/venv/lib/python3.8/site-packages/torch/serialization.py:135\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    132\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    136\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    140\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "logger = logging.getLogger(\"logger\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(logging.FileHandler(filename=\"outputs/{}.log\".format(EXPERIMENT)))\n",
    "\n",
    "run_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
